{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/sales.csv')\n",
    "df.dropna(subset=['price'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_level</th>\n",
       "      <th>maker</th>\n",
       "      <th>ingredient</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$333k</td>\n",
       "      <td>$300,492</td>\n",
       "      <td>3 Ton 90 Kg</td>\n",
       "      <td>Dec 19 2008</td>\n",
       "      <td>Q,B</td>\n",
       "      <td>advanced</td>\n",
       "      <td>M14122</td>\n",
       "      <td>IN732052,IN732053</td>\n",
       "      <td>2.76 meters</td>\n",
       "      <td>97 cm</td>\n",
       "      <td>26 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>$430,570</td>\n",
       "      <td>3 Ton 30 Kg</td>\n",
       "      <td>Sep 10 1997</td>\n",
       "      <td>J,D</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN732054,IN732055,IN732056,IN732057,IN732058</td>\n",
       "      <td>2.67 meters</td>\n",
       "      <td>98 cm</td>\n",
       "      <td>26 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$270k</td>\n",
       "      <td>$213,070</td>\n",
       "      <td>3 Ton 40 Kg</td>\n",
       "      <td>Sep 05 2001</td>\n",
       "      <td>J,D</td>\n",
       "      <td>basic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN732054,IN732059,IN732060</td>\n",
       "      <td>3.0 meters</td>\n",
       "      <td>93 cm</td>\n",
       "      <td>24 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>$229,174</td>\n",
       "      <td>3 Ton 50 Kg</td>\n",
       "      <td>Dec 23 2016</td>\n",
       "      <td>U</td>\n",
       "      <td>advanced</td>\n",
       "      <td>M14123</td>\n",
       "      <td>IN732061,IN732062,IN732063</td>\n",
       "      <td>2.5 meters</td>\n",
       "      <td>102 cm</td>\n",
       "      <td>27 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$97k</td>\n",
       "      <td>$122,659</td>\n",
       "      <td>2 Ton 970 Kg</td>\n",
       "      <td>Jan 12 2000</td>\n",
       "      <td>D,R</td>\n",
       "      <td>advanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN732064,IN732065,IN732066</td>\n",
       "      <td>2.47 meters</td>\n",
       "      <td>101 cm</td>\n",
       "      <td>26 cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cost     price        weight purchase_date product_type product_level  \\\n",
       "0  $333k  $300,492   3 Ton 90 Kg   Dec 19 2008          Q,B      advanced   \n",
       "1    NaN  $430,570   3 Ton 30 Kg   Sep 10 1997          J,D         basic   \n",
       "2  $270k  $213,070   3 Ton 40 Kg   Sep 05 2001          J,D         basic   \n",
       "3    NaN  $229,174   3 Ton 50 Kg   Dec 23 2016            U      advanced   \n",
       "4   $97k  $122,659  2 Ton 970 Kg   Jan 12 2000          D,R      advanced   \n",
       "\n",
       "    maker                                    ingredient       height   width  \\\n",
       "0  M14122                             IN732052,IN732053  2.76 meters   97 cm   \n",
       "1     NaN  IN732054,IN732055,IN732056,IN732057,IN732058  2.67 meters   98 cm   \n",
       "2     NaN                    IN732054,IN732059,IN732060   3.0 meters   93 cm   \n",
       "3  M14123                    IN732061,IN732062,IN732063   2.5 meters  102 cm   \n",
       "4     NaN                    IN732064,IN732065,IN732066  2.47 meters  101 cm   \n",
       "\n",
       "   depth  \n",
       "0  26 cm  \n",
       "1  26 cm  \n",
       "2  24 cm  \n",
       "3  27 cm  \n",
       "4  26 cm  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.to_datetime(df.purchase_date).dt.year\n",
    "train_raw = df[df.year < 2015]\n",
    "test_raw = df[df.year >= 2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Get **luxury** (**price** higher than 500k dollars) as targets for training and testing and assign them to variables **y_train** and **y_test**, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_raw['price'].map(lambda x: float(x.strip('$').replace(',',''))).map(lambda x: 1 if x > 500000 else 0)\n",
    "y_test = test_raw['price'].map(lambda x: float(x.strip('$').replace(',',''))).map(lambda x: 1 if x > 500000 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Build a transformation class to extract, preprocess, and transform **cost**; wrap up this class with **MinMaxScaler** and **LogisticRegression** to build a classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ctf', <__main__.cost_transform object at 0x000002144CF571F0>),\n",
       "                ('rescale', MinMaxScaler()),\n",
       "                ('lr', LogisticRegression(random_state=2023))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class cost_transform(object):\n",
    "    \n",
    "    def fit(self, X_train, y=None):\n",
    "        self.mean_price = X_train['cost'].map(lambda x: x if type(x) == float else float(x.strip('$').strip('k'))*1000).mean()\n",
    "        \n",
    "    def transform(self, X_train, y=None):\n",
    "        df = pd.DataFrame()\n",
    "        df['cost'] = X_train['cost'].map(lambda x: x if type(x) == float else float(x.strip('$').strip('k'))*1000)\n",
    "        return df.fillna(value = self.mean_price)\n",
    "\n",
    "    def fit_transform(self, X_train, y=None):\n",
    "        self.fit(X_train)\n",
    "        return self.transform(X_train)\n",
    "    \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "steps = [('ctf', cost_transform()),\n",
    "             ('rescale', MinMaxScaler()),\n",
    "             ('lr', LogisticRegression(random_state=2023))]\n",
    "\n",
    "model = Pipeline(steps)\n",
    "model.fit(train_raw, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is logistic regression? Is logistic regression a regression algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression estimates the probability of the ocurring of an event based on the values of independent variables.\n",
    "# Logistic regression is a classification algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Is logistic regression a linear algorithm? What is the relationship between logistic regression and linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression is not linear itself, but during the logistic regression a logit function transforms the odd of the event \n",
    "# into a log odds, after that the fitting of log odds by independent variables is linear, similar to linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What is sigmoid function? What is it for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function is a math function mapping any real values into prabability between 0 and 1. In logistic regression, sigmoid \n",
    "#  function maps the linear combinations of independent variables into the propability of the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Prediction with default settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Use the **predict** function of the model to make predictions for the training set and test set, and assign the outputs to **y_train_pred** and **y_test_pred**, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(train_raw)\n",
    "y_test_pred = model.predict(test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are the shapes of **y_train_pred** and **y_test_pred**? What do the values in **y_train_pred** and **y_test_pred** mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of y_train_pred and y_test_pred is a array of the same size to y_train and y_test, the value is 0 or 1, representing\n",
    "# whether the pridicted price is >500K or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the training and testing accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 9.40e-01\n",
      "test accuracy: 9.07e-01\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = sum(y_train_pred == y_train.values) / len(y_train)\n",
    "test_accuracy = sum(y_test_pred == y_test.values) / len(y_test)\n",
    "\n",
    "print('train accuracy: {0:.2e}'.format(train_accuracy))\n",
    "print('test accuracy: {0:.2e}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Calculate the precision, recall, and f1 scores. You can use classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non luxury       0.94      0.99      0.97      2573\n",
      "      Luxury       0.70      0.17      0.27       184\n",
      "\n",
      "    accuracy                           0.94      2757\n",
      "   macro avg       0.82      0.58      0.62      2757\n",
      "weighted avg       0.93      0.94      0.92      2757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['Non luxury', 'Luxury']\n",
    "print('Train report')\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non luxury       0.91      0.99      0.95       383\n",
      "      Luxury       0.71      0.22      0.33        46\n",
      "\n",
      "    accuracy                           0.91       429\n",
      "   macro avg       0.81      0.60      0.64       429\n",
      "weighted avg       0.89      0.91      0.88       429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test report')\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Get the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2560,   13],\n",
       "       [ 153,   31]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Train confusion matrix')\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[379,   4],\n",
       "       [ 36,  10]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test confusion matrix')\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Is this model better than the all-positive and all-negative models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I pull the testing scores from the all three models:\n",
    "# all-neg: precision = 0.00, recall = 0.00, f1 = 0.00\n",
    "# all-pos: precision = 0.11, recall = 1.00, f1 = 0.19\n",
    "# log-reg: precision = 0.71, recall = 0.22, f1 = 0.33\n",
    "\n",
    "# All positive models has best recall, logistic regression has best precision and f1, so it is better than the other two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Prediction with balanced class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Set class_weight in Logistic Regression and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ctf', <__main__.cost_transform object at 0x000002144A6368B0>),\n",
       "                ('rescale', MinMaxScaler()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(class_weight='balanced',\n",
       "                                    random_state=2023))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [('ctf', cost_transform()),\n",
    "             ('rescale', MinMaxScaler()),\n",
    "             ('lr', LogisticRegression(class_weight='balanced', random_state=2023))]\n",
    "\n",
    "model = Pipeline(steps)\n",
    "model.fit(train_raw, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Assignment:</font> Re-calcualte all the above metrics and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(train_raw)\n",
    "y_test_pred = model.predict(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 8.58e-01\n",
      "test accuracy: 8.72e-01\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = sum(y_train_pred == y_train.values) / len(y_train)\n",
    "test_accuracy = sum(y_test_pred == y_test.values) / len(y_test)\n",
    "\n",
    "print('train accuracy: {0:.2e}'.format(train_accuracy))\n",
    "print('test accuracy: {0:.2e}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non luxury       0.98      0.87      0.92      2573\n",
      "      Luxury       0.28      0.71      0.40       184\n",
      "\n",
      "    accuracy                           0.86      2757\n",
      "   macro avg       0.63      0.79      0.66      2757\n",
      "weighted avg       0.93      0.86      0.88      2757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Non luxury', 'Luxury']\n",
    "print('Train report')\n",
    "print(classification_report(y_train, y_train_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Non luxury       0.97      0.89      0.92       383\n",
      "      Luxury       0.44      0.76      0.56        46\n",
      "\n",
      "    accuracy                           0.87       429\n",
      "   macro avg       0.71      0.82      0.74       429\n",
      "weighted avg       0.91      0.87      0.89       429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test report')\n",
    "print(classification_report(y_test, y_test_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2236,  337],\n",
       "       [  54,  130]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train confusion matrix')\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[339,  44],\n",
       "       [ 11,  35]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test confusion matrix')\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Do you see any difference? Why is the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix shows more predictions are made on the minor class (luxury category), and while the precision decreas,\n",
    "# the recall and f1 values increases, so the the model's performance improves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> Which results are more reasonable? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The losistic regression with 'balanced' weight, because it accounts the imbalance of the data, which enable predicting most\n",
    "# of the minor class events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Question:</font> What are the other methods to deal with imbalanced data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 use the right metrics, besides precision, recall and f1, also consider using MCC and AUC\n",
    "# 2 Over-sampling the minor class or under-sampling the major class\n",
    "# 3 Cluster the major class first\n",
    "# 4 Use model that is suit for imbalanced data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
